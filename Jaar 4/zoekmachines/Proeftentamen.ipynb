{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Voorbeeld vragen  Deel 2\n",
    "\n",
    "## Q1  Wat is Information Retrieval?\n",
    "\n",
    "Op de eerste bladzijde van het boek MRS en ook in het eerste college hebben we uitgebreid stil gestaan bij de definitie van het begrip _information retrieval_. Er werd een definitie gegeven in 1 zin. Probeer die zin, in het Engels, zo goed mogelijk weer te geven. \n",
    "\n",
    "Je score op deze vraag hangt af van het feit of be belangrijkste concepten in de definitie ook terugkomen in jouw beschrijving.\n",
    "\n",
    "## A1\n",
    "\n",
    "Minimally the anser should contain \n",
    "* find\n",
    "* unstructured or documents\n",
    "* information need\n",
    "* large collections\n",
    "\n",
    ">definitie='''Information retrieval (IR) is finding material (usually documents) of\n",
    "an unstructured nature (usually text) that satisfies an information\n",
    "need from within large collections (usually stored on computers).\n",
    "'''\n",
    "\n",
    "## Q2  Recommender systems\n",
    "\n",
    "In de matrix factorisatie setup van recommender systemen starten we met een $m\\times n$ matrix van $m$ gebruikers en $n$ items, die gedeeltelijk gevuld is met scores die een waardering van een gebruiker voor een item aangeven. \n",
    "\n",
    "De taak is om gegeven een gebruiker, haar missende scores zo goed mogelijk te voorspellen, en op basis daarvan nog \"ongeziene\" items aan te bevelen.\n",
    "\n",
    "We _decompose_ de matrix in twee matrices van $m\\times k$ en $k\\times n$, voor een redelijk klein getal $k$ (100 of zo), op zo'n manier dat het product van deze twee de originele matrix zo goed mogelijk benadert. \n",
    "\n",
    "Nou, leg nu uit hoe we deze 2 matrices gebruiken om een aanbeveling van items te doen voor gebruiker $i$. \n",
    "\n",
    "\n",
    "## A2\n",
    "\n",
    "Pak de rij $m_i$ van gebruiker $i$ uit de $m\\times k$ matrix. Maak nu voor elke kolom $j$ waarvoor je nog geen waardering hebt in de $m\\times n$ matrix een score door het dot product te nemen van $m_i$ en $n_j$ uit de $k\\times n$ matrix. Orden die $j$'s op basis van deze score en je beveelt de hoogste aan. \n",
    "\n",
    "\n",
    "## Q  Inverted index\n",
    "\n",
    "Je hebt weer een inverted index `II` van de vorm die we steeds gebruiken, een dict met termen als sleutels en postings lists als waarden. Posting lists zijn ook weer dicts met documentids als sleutels en bijvoorbeeld term-frequenties (en allicht nog meer) als waarden.\n",
    "\n",
    "Zorg dat je hier goed mee kunt programmeren en rekenen.\n",
    "\n",
    "## Language models\n",
    "\n",
    "Sommen en voorbeelden zoals in het boek. Zorg dat je gegeven toy collecties, kansen en gesmoothe kansen kunt uitrekenen, en documenten kunt ranken gegegeven een query.\n",
    "\n",
    "## Naive Bayes Classificatie\n",
    "\n",
    "* Hoe werkt het? Hoe werkt smoothing? Kan je met voorbeelden rekenen?\n",
    "* Evalueer een systeem met de gebruikelijke maten.\n",
    "* Snap mutual information\n",
    "\n",
    "\n",
    "## Relevance feedback\n",
    "\n",
    "* Wat is het? Kan je sommetjes ermee maken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
