{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "979c499424975745fcca3890672df76e",
     "grade": false,
     "grade_id": "1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Tentamen zoekmachines Proeftentamen 2018\n",
    "\n",
    "\n",
    "\n",
    "## 1 Draai alle cellen voor je begint \n",
    "* Kies `Cell` en dan `Run all`.\n",
    "\n",
    "## 2 Draai alle cellen voordat je inlevert\n",
    "\n",
    "1. Check dat er geen syntax fouten zijn.\n",
    "\n",
    "## 3 Save je notebook en lever het in via Testvision examen.\n",
    "\n",
    "\n",
    "# Points\n",
    "\n",
    "1. Each question is worth 1 or 2 points.\n",
    "2. All autograded questions are worth 1 point, except the question about MAP which is 2 points. All manually graded questions (which you answer in a Markdown cell) are worth 2 points, excepts the one about Precision and Recall, which is 1 point.\n",
    "\n",
    "\n",
    "# Instructions\n",
    "\n",
    "* Manually graded questions are answered in MarkDown cells. Please use numbering if needed.\n",
    "* Auto-graded questions ask you to \n",
    "    * **Complete the definition of a function**, or \n",
    "    * **Assign a value to a variable** \n",
    "        * Then you see something like \n",
    "    <pre>cos = None # replace with your answer\n",
    "cos\n",
    "# JOUW CODE HIER</pre>\n",
    "        * You simply replace `None` by your answer\n",
    "* Cells with \"Hier staat een onzichtbare test\" contain autograding tests with the correct answer, which is the reason you cannot see them.\n",
    "\n",
    "> Good Luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dcbbdc0e14064e499aac9ca70bdf6744",
     "grade": false,
     "grade_id": "cell-14b8ab3339513934",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell first\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "169d26ddfa5aa37985d42442b4731b69",
     "grade": false,
     "grade_id": "3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# F1 \n",
    "\n",
    "The balanced F measure (a.k.a. F1) is defined as the harmonic mean of precision and recall. What is the advantage of using the harmonic mean rather than “averaging” (using the arithmetic mean)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "daa18519cc9bb502ece16cab784c34c1",
     "grade": true,
     "grade_id": "vraag-2",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c254a196b029b0aa9164ed4e6e3cbc70",
     "grade": false,
     "grade_id": "cell-4f5d8b6d749a7178",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Cohen's kappa\n",
    "\n",
    "Cohen's $\\kappa$ is a measure of agreement between judges which combines the actual agreement and the expected agreement.  Programm this measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "7a67f8a34d6d8be529db820a7c982063",
     "grade": false,
     "grade_id": "vraag-2-a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761194029850748\n"
     ]
    }
   ],
   "source": [
    "def CohenKappa(ActualAgreement, ExpectedAgreement):\n",
    "    return (ActualAgreement - ExpectedAgreement) / (1 - ExpectedAgreement);\n",
    "\n",
    "print(CohenKappa(0.925, 0.665));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed0b435e773e53463edbd2d8fdf8aed3",
     "grade": true,
     "grade_id": "vraag-2-t",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "356e942590fb1ab9c271347dbae9b409",
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Precision and recall \n",
    "\n",
    "An IR system returns 8 relevant documents, and 10 nonrelevant documents. There are a total of 20 relevant documents in the collection. What is the precision of the system on this search, and what is its recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "8d67b088345f37a54ed57a337ab5b644",
     "grade": false,
     "grade_id": "vraag-1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision = 8 / 18;\n",
    "Precision\n",
    "# JOUW CODE HIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b7ea781aa00a2199abc4100941e76a5",
     "grade": true,
     "grade_id": "vraag-1-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "6c18f4ea29af018dead956dbae491cb2",
     "grade": false,
     "grade_id": "vraag-1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall = 8 / 20;\n",
    "Recall\n",
    "# JOUW CODE HIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5a5acdfe10095f91ac1d66700c31cb64",
     "grade": true,
     "grade_id": "vraag-1b-test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c983766e6c6ee563bd964bbc10a19226",
     "grade": false,
     "grade_id": "ap",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Computing Recall\n",
    "\n",
    "Given a list of results and a list of relevant documents, compute the average precision.\n",
    "\n",
    "Look at the example below and use the given helper function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d4b70e8c6643243d695618057bf03581",
     "grade": false,
     "grade_id": "ap-a-h",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "# example: AP= 1/3\n",
    "\n",
    "res= [3,6,8,9]\n",
    "rel= [6,7,9]\n",
    "\n",
    "\n",
    "# helper function\n",
    "\n",
    "def relevant_indices(results,relevants):\n",
    "    '''Return the list of ranks (start counting at 1)  from results which contain a document in relevants'''\n",
    "    return [results.index(x) +1 for x in results if x in relevants]\n",
    "\n",
    "#test\n",
    "\n",
    "print(relevant_indices(res,rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "8e6159ff13938a26d6d39f8f881c7ae6",
     "grade": false,
     "grade_id": "ap-a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5550505050505051\n"
     ]
    }
   ],
   "source": [
    "res=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "rel=[1,2,9,11,15,20]\n",
    "\n",
    "def ap(results,relevants):\n",
    "    rel = 0;\n",
    "    MAP = 0;\n",
    "    rel_ind = relevant_indices(results,relevants);\n",
    "    for r in rel_ind:\n",
    "        rel += 1;\n",
    "        MAP += rel / r;        \n",
    "    return MAP/len(rel_ind)\n",
    "\n",
    "print(ap(res,rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a63f858a27ddd9af36362019a4abdea",
     "grade": true,
     "grade_id": "ap-t",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hier staat een onzichtbare test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
