{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment  week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: \n",
    "\n",
    "__Student id(s)__ : \n",
    "\n",
    "#### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Book exercises\n",
    "In this section you will make the exercises from the book, which is freely available online as a PDF at [nlp.stanford.edu/IR-book/](http://nlp.stanford.edu/IR-book/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1\n",
    "\n",
    "Are the following statements true or false?\n",
    "\n",
    "1. In a Boolean retrieval system, stemming never lowers precision.\n",
    "2. In a Boolean retrieval system, stemming never lowers recall.\n",
    "3. Stemming increases the size of the vocabulary.\n",
    "4. Stemming should be invoked at indexing time but not while processing a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> False\n",
    "  True\n",
    "  False\n",
    "  False\n",
    "  \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2\n",
    "\n",
    "Suggest what normalized form should be used for these words (including the word\n",
    "itself as a possibility):\n",
    "1. ’Cos -> cos\n",
    "2. Shi’ite -> shi ite\n",
    "3. cont’d -> cont d\n",
    "4. Hawai’i -> hawaii\n",
    "5. O’Rourke -> o rourke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3\n",
    "\n",
    "The following pairs of words are stemmed to the same form by the Porter stemmer.\n",
    "Which pairs would you argue shouldn’t be conflated. Give your reasoning.\n",
    "1. abandon/abandonment\n",
    "2. absorbency/absorbent\n",
    "3. marketing/markets\n",
    "4. university/universe\n",
    "5. volume/volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4\n",
    "\n",
    "For the Porter stemmer rule group shown in (2.1):\n",
    "1. What is the purpose of including an identity rule such as SS → SS?\n",
    "2. Applying just this rule group, what will the following words be stemmed to?\n",
    "   > _circus_ _canaries_ _boss_\n",
    "3. What rule should be added to correctly stem pony?\n",
    "4. The stemming for ponies and pony might seem strange. Does it have a deleterious effect on retrieval? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.8\n",
    "\n",
    "Assume a biword index. Give an example of a document which will be returned\n",
    "for a query of New York University but is actually a false positive which should not be\n",
    "returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "New York - York Universtiy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.9\n",
    "\n",
    "Shown below is a portion of a positional index in the format:\n",
    "> term: doc1: $\\langle$ position1, position2, . . . $\\rangle$; doc2: $\\langle$ position1, position2, . . .$\\rangle$; etc.\n",
    "\n",
    "angels: 2: $\\langle$36,174,252,651$\\rangle$; 4: $\\langle$12,22,102,432$\\rangle$; 7: $\\langle$17$\\rangle$;<br/>\n",
    "fools: 2: $\\langle$1,17,74,222$\\rangle$; 4: $\\langle$8,78,108,458$\\rangle$; 7: $\\langle$3,13,23,193$\\rangle$;<br/>\n",
    "fear: 2: $\\langle$87,704,722,901$\\rangle$; 4: $\\langle$13,43,113,433$\\rangle$; 7: $\\langle$18,328,528$\\rangle$;<br/>\n",
    "in: 2: $\\langle$3,37,76,444,851$\\rangle$; 4: $\\langle$10,20,110,470,500$\\rangle$; 7: $\\langle$5,15,25,195$\\rangle$;<br/>\n",
    "rush: 2: $\\langle$2,66,194,321,702$\\rangle$; 4: $\\langle$9,69,149,429,569$\\rangle$; 7: $\\langle$4,14,404$\\rangle$;<br/>\n",
    "to: 2: $\\langle$47,86,234,999$\\rangle$; 4: $\\langle$14,24,774,944$\\rangle$; 7: $\\langle$199,319,599,709$\\rangle$;<br/>\n",
    "tread: 2: $\\langle$57,94,333$\\rangle$; 4: $\\langle$15,35,155$\\rangle$; 7: $\\langle$20,320$\\rangle$;<br/>\n",
    "where: 2: $\\langle$67,124,393,1001$\\rangle$; 4: $\\langle$11,41,101,421,431$\\rangle$; 7: $\\langle$16,36,736$\\rangle$;\n",
    "\n",
    "Which document(s) if any match each of the following queries, where each expression\n",
    "within quotes is a phrase query?\n",
    "1. “fools rush in”\n",
    "2. “fools rush in” AND “angels fear to tread”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.10\n",
    "\n",
    "Consider the following fragment of a positional index with the format:\n",
    "\n",
    "> word: document: $\\langle$position, position, . . .$\\rangle$; document: $\\langle$position, . . .$\\rangle$<br />\n",
    ". . .\n",
    "\n",
    ">Gates: 1: $\\langle$3$\\rangle$; 2: $\\langle$6$\\rangle$; 3: $\\langle$2,17$\\rangle$; 4: $\\langle$1$\\rangle$;<br />\n",
    "IBM: 4: $\\langle$3$\\rangle$; 7: $\\langle$14$\\rangle$;<br />\n",
    "Microsoft: 1: $\\langle$1$\\rangle$; 2: $\\langle$1,21$\\rangle$; 3: $\\langle$3$\\rangle$; 5: $\\langle$16,22,51$\\rangle$;\n",
    "\n",
    "The $/k$ operator, word1 $/k$ word2 finds occurrences of word1 within $k$ words of word2 (on either side), where $k$ is a positive integer argument. Thus $k = 1$ demands that word1 be adjacent to word2.\n",
    "1. Describe the set of documents that satisfy the query Gates $/2$ Microsoft.\n",
    "2. Describe each set of values for $k$ for which the query Gates $/k$ Microsoft returns a different set of documents as the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.8\n",
    "\n",
    "Why is the idf of a term always finite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Because N is constant and df max = N and df min = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.9\n",
    "\n",
    "What is the idf of a term that occurs in every document? Compare this with the use of stop word lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> log(x/x) = 0 so the weight = 0 so it's not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.10\n",
    "\n",
    "Consider the table of term frequencies for 3 documents denoted Doc1, Doc2, Doc3 in Figure 6.9. Compute the tf-idf weights for the terms car, auto, insurance, best, for each document, using the idf values from Figure 6.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " We need df_t, idf -> doc1, doc2, doc3 tf-idf\n",
    "\n",
    "Car -> 3 log(3/3) = 0 -> 0,0,0\n",
    "\n",
    "Auto -> 2 log(3/2) = 0,176 -> 3*0,176. 33*0,176. 0\n",
    "\n",
    "Insurance -> 2 log(3/2) = 0,176 -> 0. 33*0,176. 29*0,176\n",
    "\n",
    "Best -> 2 log(3/2) = 0,176 -> 14*0,176. 0. 17*0,176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.11\n",
    "\n",
    "Can the tf-idf weight of a term in a document exceed 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Yes it can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.12\n",
    "\n",
    "How does the base of the logarithm in (6.7) affect the score calculation in (6.9)? How does the base of the logarithm affect the relative scores of two documents on a given query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.13\n",
    "\n",
    "If the logarithm in (6.7) is computed base 2, suggest a simple approximation to the idf of a term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.14\n",
    "\n",
    "If we were to stem jealous and jealousy to a common stem before setting up the vector space, detail how the definitions of tf and idf should be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> They should use the stem of the words not the term itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.15\n",
    "\n",
    "Recall the tf-idf weights computed in Exercise 6.10. Compute the Euclidean nor- malized document vectors for each of the documents, where each vector has four components, one for each of the four terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.16\n",
    "\n",
    "Verify that the sum of the squares of the components of each of the document vectors in Exercise 6.15 is 1 (to within rounding error). Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6.17\n",
    "\n",
    "With term weights as computed in Exercise 6.15, rank the three documents by computed score for the query \"car insurance\", for each of the following cases of term weighting in the query:\n",
    "\n",
    "1. The weight of a term is 1 if present in the query, 0 otherwise.\n",
    "2. Euclidean normalized idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Programming (Inverted Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Write your core python implementation here for reading and indexing the\n",
    "# dataset\n",
    "# \n",
    "# A couple of pointers to get you started:\n",
    "#  * Create a separate function to read the data and construct an index\n",
    "#  * Make sure to apply basic tokenization, lowercasing, etc.\n",
    "# \n",
    "# The exercises below each specify a function that you can implement. Try\n",
    "# not to do redo work. With proper generic functions defined here you can\n",
    "# achieve very small implementations below. Any variables and functions\n",
    "# defined here are also accessible within the answer fields below.\n",
    "# \n",
    "# Switching between the Shakespeare or Motie collection should be\n",
    "# relatively easy. It is not necessary to duplicate your entire code base\n",
    "# merely to use a different collection. Think about parts of your code\n",
    "# that will be the same, regardless of the underlying data set.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 9 Ranked Retrieval\n",
    "\n",
    "In this section we extend the boolean search engine to perform more sophisticated ranked retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9.1 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Implement the TF-IDF function 6.8 from the IR -book. So, given a query term $t$ and a document $d$, compute and return the tf-idf$_{t,d}$ score.\n",
    "\n",
    "__Hint__: Modify your earlier created inverted index, such that it also stores the document frequency for each term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tfidf(term, document):\n",
    "    \"\"\"\n",
    "    Given a single query term and a document, score the document using\n",
    "    tf-idf.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9.2 TF-IDF Ranked Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Implement the scoring function 6.9 from the IR -book. So, given a query $Q$ consisting of a number of words, compute for each document the score for this query, and print the document ids and scores in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rankedSearchTfidf(query):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the tf-idf scoring\n",
    "    scheme and print the documents and scores in decreasing order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9.3 Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now want to implement the cosine similarity function. To do this we need to vectorize documents and normalize them. We use Euclidean length for that (see section 6.3). Create a function that can vectorize and normalize a document:\n",
    "\n",
    "$normalizedVector(d) = \\frac{V(d)}{|V(d)|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def normalizedVector(document):\n",
    "    \"\"\"\n",
    "    Given a document, vectorize and normalize it\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here\n",
    "    return numpy.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9.4 Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use the normalized lengths to compute the cosine-similarity between a query and a document. I.e. implement scoring formula 6.12 from the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cosineSimilarity(query, document):\n",
    "    \"\"\"\n",
    "    Given a query and a document, compute and print the cosine-similarity\n",
    "    between the two.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9.5 Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now create a search engine which scores according to another famous scoring formula [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rankedSearchBM25(query):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the BM25 scoring\n",
    "    scheme and print the documents and scores in decreasing order\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your implementation here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
